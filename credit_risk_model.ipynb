{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d4f893",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, classification_report, confusion_matrix,\n",
    "    precision_recall_curve, roc_curve, accuracy_score, \n",
    "    precision_score, recall_score, f1_score\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "\n",
    "# ======================\n",
    "# DATA PREPARATION\n",
    "# ======================\n",
    "\n",
    "# Load and preprocess the data\n",
    "df = pd.read_csv('loan_repayment_data.csv')\n",
    "\n",
    "# Parse dates\n",
    "df['Funded_date'] = pd.to_datetime(df['Funded_date'], format='%m/%d/%Y')\n",
    "df['due_date'] = pd.to_datetime(df['due_date'], format='%m/%d/%Y')\n",
    "df['last_paid_date'] = pd.to_datetime(df['last_paid_date'], format='%m/%d/%Y')\n",
    "\n",
    "# Feature engineering\n",
    "df['days_past_due'] = (pd.to_datetime(df['last_paid_date']) - pd.to_datetime(df['due_date'])).dt.days\n",
    "df['repayment_ratio'] = df['repaid_amount'] / df['to_repay']\n",
    "df['interest_rate'] = df['interest_amount'] / df['loan_amount']\n",
    "df['loan_status_binary'] = np.where(df['loan_balance'] == 0, 0, 1)  # 0 = Fully Repaid, 1 = Outstanding\n",
    "\n",
    "df['payment_delay'] = (df['last_paid_date'] - df['due_date']).dt.days\n",
    "\n",
    "# Define target: default if repaid_amount < to_repay\n",
    "df['default'] = (df['repaid_amount'] < df['to_repay']).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd6c3ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸš€ Training LogisticRegression...\n",
      "âœ… LogisticRegression saved as LogisticRegression_model.pkl\n",
      "\n",
      "ðŸš€ Training DecisionTree...\n",
      "âœ… DecisionTree saved as DecisionTree_model.pkl\n",
      "\n",
      "ðŸš€ Training RandomForest...\n",
      "âœ… RandomForest saved as RandomForest_model.pkl\n",
      "\n",
      "ðŸš€ Training GradientBoosting...\n",
      "âœ… GradientBoosting saved as GradientBoosting_model.pkl\n",
      "\n",
      "ðŸ“Š Model Performance Summary:\n",
      "                Model  AUC-ROC  Accuracy  Precision  Recall  F1-Score\n",
      "0        DecisionTree     0.75     0.842      1.000     0.4     0.571\n",
      "1        RandomForest     0.75     0.842      1.000     0.4     0.571\n",
      "2    GradientBoosting     0.75     0.842      1.000     0.4     0.571\n",
      "3  LogisticRegression     0.60     0.632      0.375     0.6     0.462\n",
      "\n",
      "ðŸŒŸ Best performing model: DecisionTree\n"
     ]
    }
   ],
   "source": [
    "# Feature selection\n",
    "features = ['new_repeat', 'loan_duration', 'loan_amount', 'interest_amount']\n",
    "target = 'default'\n",
    "\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "\n",
    "# Identify feature types\n",
    "num_cols = ['loan_duration', 'loan_amount', 'interest_amount']\n",
    "cat_cols = ['new_repeat']\n",
    "\n",
    "# ======================\n",
    "# PREPROCESSING PIPELINE\n",
    "# ======================\n",
    "# Numerical pipeline\n",
    "num_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Categorical pipeline\n",
    "cat_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Combined preprocessor\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', num_pipeline, num_cols),\n",
    "    ('cat', cat_pipeline, cat_cols)\n",
    "])\n",
    "\n",
    "# ======================\n",
    "# MODEL TRAINING\n",
    "# ======================\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.3, \n",
    "    random_state=42, \n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "    'LogisticRegression': LogisticRegression(class_weight='balanced', max_iter=1000),\n",
    "    'DecisionTree': DecisionTreeClassifier(class_weight='balanced', random_state=42),\n",
    "    'RandomForest': RandomForestClassifier(class_weight='balanced', random_state=42),\n",
    "    'GradientBoosting': GradientBoostingClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "# Store results\n",
    "results = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nðŸš€ Training {name}...\")\n",
    "    \n",
    "    # Build pipeline with SMOTE\n",
    "    pipeline = ImbPipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('smote', SMOTE(random_state=42)),\n",
    "        ('classifier', model)\n",
    "    ])\n",
    "    \n",
    "    # Fit model\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    y_pred_proba = pipeline.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Calculate metrics\n",
    "    metrics = {\n",
    "        \"Model\": name,\n",
    "        \"AUC-ROC\": roc_auc_score(y_test, y_pred_proba),\n",
    "        \"Accuracy\": accuracy_score(y_test, y_pred),\n",
    "        \"Precision\": precision_score(y_test, y_pred),\n",
    "        \"Recall\": recall_score(y_test, y_pred),\n",
    "        \"F1-Score\": f1_score(y_test, y_pred)\n",
    "    }\n",
    "    \n",
    "    # Save model\n",
    "    joblib.dump(pipeline, f\"{name}_model.pkl\")\n",
    "    print(f\"âœ… {name} saved as {name}_model.pkl\")\n",
    "    \n",
    "    # Store results\n",
    "    results.append(metrics)\n",
    "\n",
    "# ======================\n",
    "# RESULTS ANALYSIS\n",
    "# ======================\n",
    "# Create and display results dataframe\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df.sort_values(\"AUC-ROC\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "print(\"\\nðŸ“Š Model Performance Summary:\")\n",
    "print(results_df.round(3))\n",
    "\n",
    "# Additional evaluation (optional)\n",
    "best_model_name = results_df.iloc[0]['Model']\n",
    "print(f\"\\nðŸŒŸ Best performing model: {best_model_name}\")\n",
    "\n",
    "# You can add visualization code here\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# results_df.plot(x='Model', y='AUC-ROC', kind='bar')\n",
    "# plt.title('Model Comparison: AUC-ROC Scores')\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
